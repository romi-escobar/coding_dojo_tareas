{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clasificación utilizando XGBoost (Core)**\n",
    "**Objetivo:** Implementar un pipeline completo de machine learning para un problema de clasificación utilizando XGBoost. Se hará especial énfasis en el Análisis Exploratorio de Datos (EDA), preprocesamiento, entrenamiento del modelo y optimización de hiperparámetros.\n",
    "\n",
    "**Dataset:** [Heart Disease UCI](https://www.kaggle.com/datasets/ronitf/heart-disease-uci)\n",
    "\n",
    "**Descripción del Dataset:** El dataset de enfermedades del corazón de la UCI contiene información sobre varios factores de riesgo asociados con enfermedades cardíacas. El objetivo es predecir la presencia de enfermedad cardíaca basándose en estos factores.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "**Parte 1: Carga y Exploración Inicial de Datos**\n",
    "\n",
    "1. **Carga del Dataset:**\n",
    "* Cargar el dataset desde Kaggle.\n",
    "2. **Exploración Inicial:**\n",
    "* Revisar la estructura del dataset.\n",
    "* Describir las variables y su distribución.\n",
    "* Identificar y documentar valores faltantes y outliers.\n",
    "\n",
    "**Parte 2: Análisis Exploratorio de Datos (EDA)**\n",
    "\n",
    "1. **Análisis Estadístico Descriptivo:**\n",
    "* Calcular estadísticas descriptivas básicas (media, mediana, desviación estándar, etc.).\n",
    "* Analizar la distribución de las variables categóricas.\n",
    "2. **Visualizaciones:**\n",
    "* Crear histogramas y gráficos de barras para entender la distribución de las variables.\n",
    "* Crear un mapa de calor para visualizar las correlaciones entre las variables.\n",
    "* Utilizar gráficos de dispersión para identificar posibles relaciones entre las variables.\n",
    "3. **Valores Faltantes y Outliers:**\n",
    "* Detectar y tratar valores faltantes.\n",
    "* Identificar y manejar outliers.\n",
    "\n",
    "**Parte 3: Preprocesamiento de Datos**\n",
    "\n",
    "1. **Transformación de Columnas:**\n",
    "* Codificar variables categóricas utilizando One-Hot Encoding.\n",
    "* Escalar características numéricas utilizando StandardScaler.\n",
    "2. **División del Conjunto de Datos:**\n",
    "* Dividir el dataset en conjuntos de entrenamiento y prueba. \n",
    "\n",
    "**Parte 4: Implementación de XGBoost**\n",
    "\n",
    "1. **Entrenamiento del Modelo:**\n",
    "* Entrenar un modelo de XGBoost con hiperparámetros básicos.\n",
    "* Evaluar el modelo utilizando métricas de rendimiento como la exactitud, precisión, recall, F1-Score y ROC-AUC.\n",
    "2. **Optimización de Hiperparámetros:**\n",
    "* Utilizar GridSearchCV para optimizar los hiperparámetros del modelo de XGBoost.\n",
    "* Evaluación del Modelo Optimizado:\n",
    "* Evaluar el rendimiento del modelo optimizado y compararlo con el modelo inicial."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
