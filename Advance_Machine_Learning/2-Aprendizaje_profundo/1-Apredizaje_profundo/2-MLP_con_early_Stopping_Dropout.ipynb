{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción\n",
    "MLP con Early Stopping y Dropout (Core)\n",
    "Descripción:\n",
    "\n",
    "En esta actividad, implementarás una red MLP más avanzada, utilizando técnicas como dropout y early stopping para evitar el sobreajuste. El dataset seleccionado es el «Heart Disease UCI» de Kaggle, donde se intentará predecir si un paciente tiene una enfermedad cardíaca o no basándose en varias características.\n",
    "\n",
    "Enlace al dataset: https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "\n",
    "\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "El objetivo de esta actividad es entrenar una red MLP utilizando dropout para regularizar la red y early stopping para detener el entrenamiento cuando el rendimiento en el conjunto de validación deje de mejorar. Al final, se comparará el rendimiento de este modelo con el de un MLP básico.\n",
    "\n",
    "\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "1. Carga de datos:\n",
    "  – Descarga el dataset «Heart Disease UCI» de Kaggle. Explora las características que están relacionadas con la edad, el sexo, la presión arterial y otras variables clínicas.\n",
    "  – Verifica si hay valores nulos en el dataset y realiza el preprocesamiento necesario, como la imputación de valores faltantes y la normalización de las variables numéricas.\n",
    "\n",
    "2. Exploración y preprocesamiento de datos:\n",
    "  – Realiza una división del dataset en conjunto de entrenamiento y prueba. Asegúrate de que el dataset esté bien balanceado, verificando la distribución de la variable objetivo (enfermedad cardíaca sí/no).\n",
    "\n",
    "3. Implementación de la MLP con Dropout:\n",
    "  – Implementa una red MLP con dos capas ocultas utilizando Keras o cualquier biblioteca de deep learning.\n",
    "  – Agrega capas de dropout después de cada capa oculta para reducir el riesgo de sobreajuste. Utiliza una tasa de dropout del 20-30%.\n",
    "  – Implementa el early stopping para detener el entrenamiento cuando la precisión en el conjunto de validación deje de mejorar después de varias épocas (por ejemplo, paciencia de 5 épocas).\n",
    "\n",
    "4. Entrenamiento del modelo:\n",
    "  – Entrena el modelo con early stopping activado, utilizando el optimizador Adam y la función de pérdida binaria (binary_crossentropy). Entrena durante un máximo de 100 épocas.\n",
    "  – Visualiza las curvas de aprendizaje para observar cómo evoluciona la pérdida y la precisión a lo largo del entrenamiento, especialmente con early stopping activado.\n",
    "\n",
    "5. Evaluación del modelo:\n",
    "  – Evalúa el modelo en el conjunto de prueba y compara las métricas de rendimiento, como precisión, recall, F1-score y matriz de confusión.\n",
    "  – Discute cómo el uso de dropout y early stopping ha afectado el rendimiento en comparación con un MLP básico sin estas técnicas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
